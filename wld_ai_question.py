# -*- coding: utf-8 -*-
"""wld_ai_question.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oaL6vQvkqqRymJeMTCxFm0WccMiK39Kl

**Image Classification Question - Wearable Devices**

1.   Import Python libraries (you can add your own)
2.   Mount your Google Drive (don't forget to upload the "*WLD_AI*" directory to the root of your drive - under "*My Drive*")
3.   Read the database and view some of the images
4.   Come up with features to differentiate between <font color='green'>*forest*</font> and <font color='gray'>*glacier*</font> images
5.   Visualize features with a scatter plot
6.   Train your algorithm on the training set and evaluate *accuracy* on the test set
7.   Explain your solution using *text blocks*
8.   BONUS - Repeat 1-7 for <font color='brown'>*mountain*</font> and <font color='gray'>*buildings*</font> images (call "*read_db()*" with *mountain_buildings_train.pkl* and *mountain_buildings_test.pkl*)
8. Send your solution (this file) to Wearable Devices

Good Luck! 

**Important** - a well written explanation of your solution is more important than an accurate solution!

Import libraries
"""

import matplotlib.pyplot as plt
import pickle
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms
import cv2
from google.colab import drive
from skimage.transform import resize
from skimage.color import rgb2gray

"""Mount your Google Drive"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

"""Read Train and Test datasets - Check out the images"""

#======================================INTRODUTION========================================================
'''
This code is for training a convolutional neural network (CNN) model on a dataset of images. 
The model takes in flattened, scaled grayscale images as input and outputs a classification prediction for each image.

The model starts by loading a pre-trained CNN model using the tf.keras.applications.ResNet50 function. 
The layers of this pre-trained model are then frozen, or made untrainable, using a for loop.

Next, a new classification layer is added on top of the pre-trained CNN model. 
This layer consists of a fully connected (dense) layer with 256 units and a rectified linear unit (ReLU) activation function, 
a dropout layer with a dropout rate of 0.5, and a final dense layer with 2 units and a softmax activation function.

The pre-trained CNN and the new classification layer are then combined to form the final model using the tf.
keras.models.Model function. The model is then compiled using the compile method, specifying a loss function of categorical_crossentropy, 
an optimizer of adam, and a metric of accuracy.

Finally, the model is trained using the fit method, specifying the training and validation data (X_train, y_train, X_val, 
and y_val), the number of epochs (20), and the batch size (32). The training history is stored in the history variable.



_Description of the variables used in this code:
________________________________________________________________________________________________________________________
-images_train: A list of images in the training dataset.

-classes_train: A list of the class labels for the images in the training dataset.

-images_test: A list of images in the testing dataset.

-classes_test: A list of the class labels for the images in the testing dataset.

-images_train_resized: A list of the images in the training dataset, resized to a common size of (224, 224).

-images_test_resized: A list of the images in the testing dataset, resized to a common size of (224, 224).

-images_train_gray: A numpy array of the images in the training dataset, converted to grayscale.

-images_test_gray: A numpy array of the images in the testing dataset, converted to grayscale.

-scaler: A StandardScaler object for scaling the grayscale images.

-images_train_gray_scaled: A numpy array of the grayscale images in the training dataset, scaled using the scaler object.

-images_test_gray_scaled: A numpy array of the grayscale images in the testing dataset, scaled using the scaler object.

-num_features: The number of features (pixels) in each image after flattening.

-images_train_gray_scaled_flattened: A numpy array of the flattened, scaled grayscale images in the training dataset.

-images_test_gray_scaled_flattened: A numpy array of the flattened, scaled grayscale images in the testing dataset.

-num_classes: The number of classes in the dataset (2).

-classes_train_one_hot: A one-hot encoded numpy array of the class labels for the training dataset.

-classes_test_one_hot: A one-hot encoded numpy array of the class labels for the testing dataset.

-X_train: A numpy array of the training images, used as input to the model.

-X_val: A numpy array of the validation images, used as input to the model.

-y_train: A numpy array of the training class labels, used as target output for the model.

-y_val: A numpy array of the validation class labels, used as target output for the model.

-model: The CNN model.

-output: The output of the pre-trained CNN model.

-predictions: The output of the model, after passing through the classification layer.

-history: A record of the training history of the model, including the training and validation loss and accuracy at each epoch.
__________________________________________________________________________________________________________________________________
'''


#======================================READ_IMAGES========================================================
# Read Database 
'''
takes in a file path as input and returns the images and classes contained in that file.
'''
def read_db(path):
  with open(path, 'rb') as handle:
    images = pickle.load(handle)
    classes = pickle.load(handle)
    return images, classes

# Read Train set
'''
training/testing  set and assigns the returned images 
and classes to the variables images_train and classes_train, respectively.
'''
images_train, classes_train = read_db('/content/drive/My Drive/WLD_AI/forest_glacier_train.pkl')

# Read Test Set
images_test, classes_test = read_db('/content/drive/My Drive/WLD_AI/forest_glacier_test.pkl')
original_array = np.random.rand(10, 64, 64, 3)
flattened_array = original_array.reshape(10, -1)


#======================================LOAD_DATA_INTO_TENSOR========================================================
# Resize the images to a common size
'''
resizes the images in the images_train and images_test arrays to a common size of (224, 224) using the resize function.
'''
images_train_resized = [resize(im, (224, 224)) for im in images_train]
images_test_resized = [resize(im, (224, 224)) for im in images_test]

# Convert the images to grayscale
'''
converts the resized images to grayscale using the rgb2gray function from the skimage.color module.
 The grayscale images are then converted to a numpy array and stored in the images_train_gray and images_test_gray arrays.
'''
images_train_gray = np.array([rgb2gray(im) for im in images_train_resized])
images_test_gray = np.array([rgb2gray(im) for im in images_test_resized])


# Scale the images
'''
scales the grayscale images using a StandardScaler object, and then flattens the resulting images into one-dimensional arrays. 
These flattened, scaled images are stored in the images_train_gray_scaled_flattened and images_test_gray_scaled_flattened arrays.
'''
scaler = StandardScaler()
images_train_gray_scaled = scaler.fit_transform(images_train_gray.reshape(-1, 1)).reshape(-1, *images_train_gray.shape)
images_test_gray_scaled = scaler.transform(images_test_gray.reshape(-1, 1)).reshape(-1, *images_test_gray.shape)

# Flatten the images
'''
flattens the images_train_gray_scaled and images_test_gray_scaled arrays into one-dimensional arrays, 
and stores the resulting arrays in the images_train_gray_scaled_flattened
and images_test_gray_scaled_flattened arrays respectively.
'''

num_features = images_train_gray_scaled.shape[1] * images_train_gray_scaled.shape[2]
images_train_gray_scaled_flattened = images_train_gray_scaled.reshape(-1, num_features)
images_test_gray_scaled_flattened = images_test_gray_scaled.reshape(images_test_gray_scaled.shape[0], -1)


#======================================PREPAR_DATA========================================================
# Convert images to grayscale and scale them
images_train_gray = np.array([cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in images_train]) # Convert images to grayscale
images_test_gray = np.array([cv2.cvtColor(im, cv2.COLOR_BGR2GRAY) for im in images_test]) # Convert images to grayscale
scaler = StandardScaler() # Initialize scaler
images_train_gray_scaled = scaler.fit_transform(images_train_gray.reshape(-1, 1)).reshape(-1, *images_train_gray.shape) # Scale training images
images_test_gray_scaled = scaler.transform(images_test_gray.reshape(-1, 1)).reshape(-1, *images_test_gray.shape) # Scale test images

# Flatten images
num_features = images_train_gray_scaled.shape[1] * images_train_gray_scaled.shape[2] # Calculate number of features
images_train_gray_scaled_flattened = images_train_gray_scaled.reshape(-1, num_features) # Flatten training images
images_test_gray_scaled_flattened = images_test_gray_scaled.reshape(-1, num_features) # Flatten test images

def one_hot_encode(labels, num_classes):
  one_hot = np.zeros((len(labels), num_classes))
  one_hot[np.arange(len(labels)), labels] = 1
  return one_hot

num_classes = 2 # Set number of classes
classes_train_one_hot = one_hot_encode(classes_train, num_classes) # One-hot encode training labels
classes_test_one_hot = one_hot_encode(classes_test, num_classes) # One-hot encode test labels

# Split the training data into a training set and a validation set
X_train, X_val, y_train, y_val = train_test_split(images_train_gray_scaled_flattened, classes_train_one_hot, test_size=0.2, random_state=42)

#======================================MODEL========================================================
# Load the pre-trained CNN model
model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of the model
for layer in model.layers:
  layer.trainable = False  # Freeze layers

# Add a new classification layer on top of the CNN
output = model.output
output = tf.keras.layers.Flatten()(output)
output = tf.keras.layers.Dense(256, activation='relu')(output)
output = tf.keras.layers.Dropout(0.5)(output)
predictions = tf.keras.layers.Dense(2, activation='softmax')(output)

# Create a new model with the CNN and the new classification layer
model = tf.keras.models.Model(inputs=model.input, outputs=predictions)

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32)


# Show some of the images
for ii in range(6):
    plt.subplot(2, 3, ii + 1)
    rand_im = np.random.randint(0, len(images_test))
    im = images_test[rand_im]
    plt.imshow(im)
    plt.xticks([])
    plt.yticks([])

"""<font color='blue'>**Todo**</font>: Engineer you features

<font color='blue'>**Todo**</font>: Visualize feature space with a scatter plot

Use a <font color='green'>green</font> color for forest embedding and a <font color='gray'>gray</font> color for glacier embedding

<font color='blue'>**Todo**</font>: Evaluate your accuracy
"""